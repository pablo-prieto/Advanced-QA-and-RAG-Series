{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "print(load_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "azure_openai_endpoint = os.environ[\"OPENAI_API_BASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_client = OpenAI(\n",
    "  api_key = azure_openai_api_key\n",
    ")\n",
    "chroma_client = chromadb.PersistentClient(path=str(here(\"data/chroma\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a collection for data injection**\n",
    "\n",
    "Throws an error if the table already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"datasets_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = here(\"data/for_upload/datasets_rows.csv\")\n",
    "df = pd.read_csv(file_dir, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>is_active</th>\n",
       "      <th>version</th>\n",
       "      <th>status</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>viewed_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>is_shared</th>\n",
       "      <th>organization_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Cars</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>CSV</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-18 04:17:42.552+00</td>\n",
       "      <td>2024-11-18 04:17:42.552+00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Random</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>CSV</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-18 04:29:59.159+00</td>\n",
       "      <td>2024-11-18 04:29:59.159+00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>CSV</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-21 02:01:07.822+00</td>\n",
       "      <td>2024-11-21 02:01:07.822+00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id  user_id    name dataset_type file_extension  is_active  \\\n",
       "0           3        1    Cars         TEXT            CSV       True   \n",
       "1           4        1  Random         TEXT            CSV       True   \n",
       "2           5        2    Test         TEXT            CSV       True   \n",
       "\n",
       "   version  status  dataset_size  viewed_at                  created_at  \\\n",
       "0      NaN     NaN           366        NaN  2024-11-18 04:17:42.552+00   \n",
       "1      NaN     NaN           732        NaN  2024-11-18 04:29:59.159+00   \n",
       "2      NaN     NaN         13192        NaN  2024-11-21 02:01:07.822+00   \n",
       "\n",
       "                   updated_at  is_shared  organization_id  \n",
       "0  2024-11-18 04:17:42.552+00      False              NaN  \n",
       "1  2024-11-18 04:29:59.159+00      False              NaN  \n",
       "2  2024-11-21 02:01:07.822+00      False              NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Process in chunks if dataset is big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "embeddings = []\n",
    "for index, row in df.iterrows():\n",
    "    output_str = \"\"\n",
    "    # Treat each row as a separate chunk\n",
    "    for col in df.columns:\n",
    "        output_str += f\"{col}: {row[col]},\\n\"\n",
    "    response = azure_client.embeddings.create(\n",
    "        input = output_str,\n",
    "        model= \"text-embedding-3-small\"\n",
    "    )\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "    docs.append(output_str)\n",
    "    metadatas.append({\"source\": \"datasets_rows\"})\n",
    "    ids.append(f\"id{index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset_id: 3,\\nuser_id: 1,\\nname: Cars,\\ndataset_type: TEXT,\\nfile_extension: CSV,\\nis_active: True,\\nversion: nan,\\nstatus: nan,\\ndataset_size: 366,\\nviewed_at: nan,\\ncreated_at: 2024-11-18 04:17:42.552+00,\\nupdated_at: 2024-11-18 04:17:42.552+00,\\nis_shared: False,\\norganization_id: nan,\\n',\n",
       " 'dataset_id: 4,\\nuser_id: 1,\\nname: Random,\\ndataset_type: TEXT,\\nfile_extension: CSV,\\nis_active: True,\\nversion: nan,\\nstatus: nan,\\ndataset_size: 732,\\nviewed_at: nan,\\ncreated_at: 2024-11-18 04:29:59.159+00,\\nupdated_at: 2024-11-18 04:29:59.159+00,\\nis_shared: False,\\norganization_id: nan,\\n',\n",
       " 'dataset_id: 5,\\nuser_id: 2,\\nname: Test,\\ndataset_type: TEXT,\\nfile_extension: CSV,\\nis_active: True,\\nversion: nan,\\nstatus: nan,\\ndataset_size: 13192,\\nviewed_at: nan,\\ncreated_at: 2024-11-21 02:01:07.822+00,\\nupdated_at: 2024-11-21 02:01:07.822+00,\\nis_shared: False,\\norganization_id: nan,\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 'datasets_rows'}, {'source': 'datasets_rows'}, {'source': 'datasets_rows'}]\n",
      "['id0', 'id1', 'id2']\n"
     ]
    }
   ],
   "source": [
    "print(metadatas)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.015110057778656483,\n",
       " -0.02865656279027462,\n",
       " 0.023209765553474426,\n",
       " -0.029528051614761353,\n",
       " 0.02415814995765686,\n",
       " -0.057723239064216614,\n",
       " -0.01983916014432907,\n",
       " -0.008785364218056202,\n",
       " -0.014981897547841072,\n",
       " -0.02452981285750866]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=docs,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the vectorDB creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in vectordb: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vectors in vectordb:\", collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-embedding-3-small\"\n",
    "azure_openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "azure_openai_endpoint = os.environ[\"OPENAI_API_BASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform similarity search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate embedding for Records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_texts = \"what's the name of the dataset with dataset_id = 4?\"\n",
    "# query_texts = \"Using the schema from {schema_name} and associated records from {schema_samples}, match records from source {source_name} and return the table name and column name associated with each cell in the record.\"\n",
    "query_texts = \"Using the schema from {schema_name} and associated records from {schema_samples}, match records from input {input_name} return closest records.\"\n",
    "response = azure_client.embeddings.create(\n",
    "        input = query_texts,\n",
    "        model= model_name\n",
    "    )\n",
    "query_embeddings = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_texts = \"what's the name of the dataset with dataset_id = 4?\"\n",
    "query_texts = \"in the collection {name}, find the closest matching table and column names to the query {query}.\"\n",
    "response = azure_client.embeddings.create(\n",
    "        input = query_texts,\n",
    "        model= model_name\n",
    "    )\n",
    "query_embeddings = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0029961096588522196, -0.01976878196001053, 0.03094029799103737, -0.004394088871777058, 0.01625843718647957, 0.0034641555976122618, -0.017637940123677254, 0.02667861618101597, -0.020433899015188217, -0.042937055230140686]\n"
     ]
    }
   ],
   "source": [
    "# query_texts = \"what's the name of the dataset with dataset_id = 4?\"\n",
    "query_texts = \"in the collection {name}, find the closest matching table and column names to the query {query}.\"\n",
    "response = azure_client.embeddings.create(\n",
    "        input = query_texts,\n",
    "        model= model_name\n",
    "    )\n",
    "query_embeddings = response.data[0].embedding\n",
    "print(query_embeddings[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the chromaDB collection for vector search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = chroma_client.get_collection(name=\"datasets_rows\")\n",
    "vectordb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectordb.query(\n",
    "    query_embeddings = query_embeddings,\n",
    "    n_results=1 #top_k\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the results to an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role = \"You will recieve the user's question along with the search results of that question over a database. Generate SQL insert statements based on those answers for each respective table.\"\n",
    "prompt = f\"User's question: {query_texts} \\n\\n Search results:\\n {results}\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        system_role\n",
    "        )},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = azure_client.chat.completions.create(\n",
    "    model=os.getenv(\"gpt_deployment_name\"),\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-raggpt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
