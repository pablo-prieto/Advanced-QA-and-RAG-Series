{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/use_cases/sql/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from pyprojroot import here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connecting to the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(here(\"data\")) + \"/csv_xlsx_sqldb.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.utilities.sql_database.SQLDatabase at 0x7f128f98fb60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['actions_rows', 'static_actions_rows']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(133, '2021-02-28 22:40:32+00', 1, 'Hydro Blockchain Migration.', '2021-01-28 05:00:00+00', 'https://projecthydro.medium.com/hydro-smart-contract-redeployment-57bf0e1f3fb4', '9c2aa1b1-4009-451e-a8e9-472dbba214c6', None, 'The Old ERC20 contract address is 0xebbdf302c940c6bfd49c6b165f457fdb324649bc; upgraded HYDRO contract addresses are 0x946112efaB61C3636CBD52DE2E1392D7A75A6f01 (ERC20) and 0xf3DBB49999B25c9D6641a9423C7ad84168D00071 (BEP20)'), (134, '2019-04-18 05:59:26+00', 1, 'Binance Coin Ethereum - Binance Chain Mainnet Swap', '2018-12-04 08:51:00+00', 'https://www.binance.com/en/support/announcement/360027114471', 'f25bd7b6-148f-461a-8d78-6b5dbd7f7258', 'https://twitter.com/binance/status/1069876962955452416', 'We are excited to announce that the Binance Chain mainnet has been launched. Public access and BNB mainnet swap will begin on 2019/04/23 2:00 AM (UTC).'), (135, '2020-11-09 11:22:00+00', 1, 'Stratis STRAX Blockchain Migration.', '2020-09-25 00:00:00+00', 'https://www.stratisplatform.com/2020/09/25/introducing-strax/', '15a5aac6-e5e8-47c4-bd4f-6d0de21608c2', 'https://www.stratisplatform.com/2020/09/25/introducing-strax/', 'The creation of the STRAX Blockchain provides a vanilla environment for the STRAX Foundation to begin rapid growth, utilizing the blockchain technology platform that has been developed over the past three years.'), (136, '2021-04-20 00:00:00+00', 1, 'SNM BEP20 Blockchain Migration', None, 'https://sonm.medium.com/sonm-snm-token-upgrade-and-redenomination-plan-b2e2b825a755', 'b205b773-5beb-4c85-a98b-9fd7dba0ec47', None, 'SONM will conduct a token upgrade plan from April 20 on, aiming to establish a hybrid ERC-20+BEP-20 token metrics.'), (137, '2021-07-28 00:00:00+00', 1, 'EXRD ERC20 Blockchain Migration to Radix Mainnet.', '2021-06-02 00:00:00+00', 'https://www.radixdlt.com/post/radix-olympia-mainnet-is-coming', '41a070a0-5126-45e8-b692-c300d1b41bc4', None, 'After years of research and development, the first version of the Radix Public Network, Olympia, is launching on July 28th, 2021.'), (138, '2021-03-31 00:00:00+00', 1, 'Porta Network Mainnet Blockchain Migration.', None, 'https://porta-network.notion.site/porta-network/3b926dc9402f40488301a148c21fc5aa?v=7e446dab170a4c2896f8e42252a1116f', '1121debb-90cc-41e3-94ed-43302628edd5', None, 'Porta Network Blockchain Migration planned for Q1 2022.'), (139, '2021-09-18 12:57:00+00', 1, 'ZB.COM Bytom (BTM) Blockchain Migration.', None, 'https://www.zb.com/help/notices/proclamation/1599', 'f85255dc-30a3-4810-b303-583185dab1b7', None, 'The Bytom 2.0 mainnet upgrade is complete. All BTM tokens of our users have been automatically mapped to the Bytom 2.0 mainnet token.'), (140, '2021-08-19 20:24:17+00', 1, 'Bibox Bytom (BTM) Blockchain Migration.', None, 'https://support.bibox.jp/hc/en-us/articles/4405196500633-Bibox-Announcement-on-Supporting-BTM-Project-Upgrade', 'e14ae6f3-e560-4ed8-a6d1-911088c7066e', None, 'Bibox will soon support the upgrade of Bytom (BTM) project.'), (141, '2021-08-19 20:24:17+00', 1, 'Gate.io Bytom (BTM) Blockchain Migration.', None, 'https://www.gate.io/article/21951', 'ede53346-59c6-4b2e-a7a0-f6ceb63e8369', None, 'According to the Bytom team, Bytom mainnet 2.0 will go live soon and the old BTM tokens will be swapped for the new BTM tokens at the ratio of 1:1 based on snapshot at block height 709,660.'), (142, '2021-08-20 00:00:00+00', 1, 'Bittrex Bytom (BTM) Blockchain Migration.', None, 'https://medium.com/bytomofficial/bytom-2-0-q-a-all-you-need-to-know-about-bytom-2-0-b93e95dad900', '3d11302e-4aa1-48ae-adc2-b15599ef35d3', None, 'We’re taking Bytom to the next level by launching Bytom 2.0.')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the connection to the vectordb\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM actions_rows LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the access to the environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables are loaded: True\n",
      "test by reading a variable: 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(\"Environment variables are loaded:\", load_dotenv())\n",
    "print(\"test by reading a variable:\", os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test your GPT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        \"You are a helpful assistant\"\n",
    "    )},\n",
    "    {\"role\": \"user\", \"content\": str(\"hello\")}\n",
    "]\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"gpt_deployment_name\"),\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. SQL query chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = os.getenv(\"gpt_deployment_name\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model_name=model_name,\n",
    "    temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) as total_actions\n",
      "FROM actions_rows;\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many actions are there?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the query to make sure it’s valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(407,)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add QuerySQLDataBaseTool to the chain**\n",
    "Execute SQL query\n",
    "\n",
    "**This is the most dangerous part of creating a SQL chain.** Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "We can use the QuerySQLDatabaseTool to easily add query execution to our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_730/3612510648.py:4: LangChainDeprecationWarning: The class `QuerySQLDataBaseTool` was deprecated in LangChain 0.3.12 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-community package and should be used instead. To use it run `pip install -U :class:`~langchain-community` and import as `from :class:`~langchain_community.tools import QuerySQLDatabaseTool``.\n",
      "  execute_query = QuerySQLDataBaseTool(db=db)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[(407,)]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "chain = write_query | execute_query\n",
    "\n",
    "chain.invoke({\"question\": \"How many actions are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer the question in a user friendly manner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are a total of 407 actions.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many actions are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Agents**\n",
    "\n",
    "Agent which provides a more flexible way of interacting with SQL databases. The main advantages of using the SQL Agent are:\n",
    "\n",
    "- It can answer questions based on the databases’ schema as well as on the databases’ content (like describing a specific table).\n",
    "- It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
    "- It can answer questions that require multiple dependent queries.\n",
    "- It will save tokens by only considering the schema from relevant tables.\n",
    "\n",
    "To initialize the agent, we use create_sql_agent function. This agent contains the SQLDatabaseToolkit which contains tools to:\n",
    "\n",
    "- Create and execute queries\n",
    "- Check query syntax\n",
    "- Retrieve table descriptions\n",
    "- …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True, max_execution_time = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mactions_rows, static_actions_rows\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'actions_rows, static_actions_rows'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE actions_rows (\n",
      "\taction_id BIGINT, \n",
      "\teffective_time TEXT, \n",
      "\tstatic_event_id BIGINT, \n",
      "\tdescription TEXT, \n",
      "\tannounce_time TEXT, \n",
      "\turl TEXT, \n",
      "\tevent_id TEXT, \n",
      "\tannounce_url TEXT, \n",
      "\tcomment TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from actions_rows table:\n",
      "action_id\teffective_time\tstatic_event_id\tdescription\tannounce_time\turl\tevent_id\tannounce_url\tcomment\n",
      "133\t2021-02-28 22:40:32+00\t1\tHydro Blockchain Migration.\t2021-01-28 05:00:00+00\thttps://projecthydro.medium.com/hydro-smart-contract-redeployment-57bf0e1f3fb4\t9c2aa1b1-4009-451e-a8e9-472dbba214c6\tNone\tThe Old ERC20 contract address is 0xebbdf302c940c6bfd49c6b165f457fdb324649bc; upgraded HYDRO contrac\n",
      "134\t2019-04-18 05:59:26+00\t1\tBinance Coin Ethereum - Binance Chain Mainnet Swap\t2018-12-04 08:51:00+00\thttps://www.binance.com/en/support/announcement/360027114471\tf25bd7b6-148f-461a-8d78-6b5dbd7f7258\thttps://twitter.com/binance/status/1069876962955452416\tWe are excited to announce that the Binance Chain mainnet has been launched. Public access and BNB m\n",
      "135\t2020-11-09 11:22:00+00\t1\tStratis STRAX Blockchain Migration.\t2020-09-25 00:00:00+00\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\t15a5aac6-e5e8-47c4-bd4f-6d0de21608c2\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\tThe creation of the STRAX Blockchain provides a vanilla environment for the STRAX Foundation to begi\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE static_actions_rows (\n",
      "\tstatic_action_id BIGINT, \n",
      "\tname TEXT, \n",
      "\tacronym TEXT, \n",
      "\tdescription TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from static_actions_rows table:\n",
      "static_action_id\tname\tacronym\tdescription\n",
      "1\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "2\tContract Migration\tCTMIG\tThe migration of an asset contract from one blockchain contract address to a new one.\n",
      "3\tRebrand\tNAMG\tChange in the name, ticker or other identifying characteristic of an asset.\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT COUNT(*) AS total_actions FROM actions_rows WHERE description LIKE '%Blockchain%';\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(10,)]\u001b[0m\u001b[32;1m\u001b[1;3mThere are 10 actions in the database that have to do with Blockchains.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many actions have to do with Blockchains?',\n",
       " 'output': 'There are 10 actions in the database that have to do with Blockchains.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"How many actions have to do with Blockchains?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mactions_rows, static_actions_rows\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'actions_rows, static_actions_rows'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE actions_rows (\n",
      "\taction_id BIGINT, \n",
      "\teffective_time TEXT, \n",
      "\tstatic_event_id BIGINT, \n",
      "\tdescription TEXT, \n",
      "\tannounce_time TEXT, \n",
      "\turl TEXT, \n",
      "\tevent_id TEXT, \n",
      "\tannounce_url TEXT, \n",
      "\tcomment TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from actions_rows table:\n",
      "action_id\teffective_time\tstatic_event_id\tdescription\tannounce_time\turl\tevent_id\tannounce_url\tcomment\n",
      "133\t2021-02-28 22:40:32+00\t1\tHydro Blockchain Migration.\t2021-01-28 05:00:00+00\thttps://projecthydro.medium.com/hydro-smart-contract-redeployment-57bf0e1f3fb4\t9c2aa1b1-4009-451e-a8e9-472dbba214c6\tNone\tThe Old ERC20 contract address is 0xebbdf302c940c6bfd49c6b165f457fdb324649bc; upgraded HYDRO contrac\n",
      "134\t2019-04-18 05:59:26+00\t1\tBinance Coin Ethereum - Binance Chain Mainnet Swap\t2018-12-04 08:51:00+00\thttps://www.binance.com/en/support/announcement/360027114471\tf25bd7b6-148f-461a-8d78-6b5dbd7f7258\thttps://twitter.com/binance/status/1069876962955452416\tWe are excited to announce that the Binance Chain mainnet has been launched. Public access and BNB m\n",
      "135\t2020-11-09 11:22:00+00\t1\tStratis STRAX Blockchain Migration.\t2020-09-25 00:00:00+00\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\t15a5aac6-e5e8-47c4-bd4f-6d0de21608c2\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\tThe creation of the STRAX Blockchain provides a vanilla environment for the STRAX Foundation to begi\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE static_actions_rows (\n",
      "\tstatic_action_id BIGINT, \n",
      "\tname TEXT, \n",
      "\tacronym TEXT, \n",
      "\tdescription TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from static_actions_rows table:\n",
      "static_action_id\tname\tacronym\tdescription\n",
      "1\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "2\tContract Migration\tCTMIG\tThe migration of an asset contract from one blockchain contract address to a new one.\n",
      "3\tRebrand\tNAMG\tChange in the name, ticker or other identifying characteristic of an asset.\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT AR1.action_id, AR1.description, AR1.comment, SAR1.description FROM actions_rows AR1 INNER JOIN static_actions_rows SAR1 ON AR1.static_event_id=SAR1.static_action_id ORDER BY AR1.effective_time DESC LIMIT 1'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(242, 'Asset is abandoned by official entity and no longer supported.', 'Tether Updates Users on a Strategic Transition to Better Support Community-Driven Product Support')]\u001b[0m\u001b[32;1m\u001b[1;3mThe most recent action, its description, its comment, and the static event description are as follows:\n",
      "- Description: Asset is abandoned by official entity and no longer supported.\n",
      "- Comment: Tether Updates Users on a Strategic Transition to Better Support Community-Driven Product Support\n",
      "- Static Event Description: Migration of an asset from one blockchain protocol to another blockchain protocol.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Provide me only the most recent action, its description, its comment and the static event description in a comma separated list.',\n",
       " 'output': 'The most recent action, its description, its comment, and the static event description are as follows:\\n- Description: Asset is abandoned by official entity and no longer supported.\\n- Comment: Tether Updates Users on a Strategic Transition to Better Support Community-Driven Product Support\\n- Static Event Description: Migration of an asset from one blockchain protocol to another blockchain protocol.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Provide me only the most recent action, its description, its comment and the static event description in a comma separated list.\"})\n",
    "# agent_executor.invoke(\"Describe the playlisttrack table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been uploaded to the database.\n",
      "sqlite\n",
      "['actions_rows', 'static_actions_rows', 'temp_table']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mactions_rows, static_actions_rows, temp_table\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'actions_rows, static_actions_rows, temp_table'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE actions_rows (\n",
      "\taction_id BIGINT, \n",
      "\teffective_time TEXT, \n",
      "\tstatic_event_id BIGINT, \n",
      "\tdescription TEXT, \n",
      "\tannounce_time TEXT, \n",
      "\turl TEXT, \n",
      "\tevent_id TEXT, \n",
      "\tannounce_url TEXT, \n",
      "\tcomment TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from actions_rows table:\n",
      "action_id\teffective_time\tstatic_event_id\tdescription\tannounce_time\turl\tevent_id\tannounce_url\tcomment\n",
      "133\t2021-02-28 22:40:32+00\t1\tHydro Blockchain Migration.\t2021-01-28 05:00:00+00\thttps://projecthydro.medium.com/hydro-smart-contract-redeployment-57bf0e1f3fb4\t9c2aa1b1-4009-451e-a8e9-472dbba214c6\tNone\tThe Old ERC20 contract address is 0xebbdf302c940c6bfd49c6b165f457fdb324649bc; upgraded HYDRO contrac\n",
      "134\t2019-04-18 05:59:26+00\t1\tBinance Coin Ethereum - Binance Chain Mainnet Swap\t2018-12-04 08:51:00+00\thttps://www.binance.com/en/support/announcement/360027114471\tf25bd7b6-148f-461a-8d78-6b5dbd7f7258\thttps://twitter.com/binance/status/1069876962955452416\tWe are excited to announce that the Binance Chain mainnet has been launched. Public access and BNB m\n",
      "135\t2020-11-09 11:22:00+00\t1\tStratis STRAX Blockchain Migration.\t2020-09-25 00:00:00+00\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\t15a5aac6-e5e8-47c4-bd4f-6d0de21608c2\thttps://www.stratisplatform.com/2020/09/25/introducing-strax/\tThe creation of the STRAX Blockchain provides a vanilla environment for the STRAX Foundation to begi\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE static_actions_rows (\n",
      "\tstatic_action_id BIGINT, \n",
      "\tname TEXT, \n",
      "\tacronym TEXT, \n",
      "\tdescription TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from static_actions_rows table:\n",
      "static_action_id\tname\tacronym\tdescription\n",
      "1\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "2\tContract Migration\tCTMIG\tThe migration of an asset contract from one blockchain contract address to a new one.\n",
      "3\tRebrand\tNAMG\tChange in the name, ticker or other identifying characteristic of an asset.\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE temp_table (\n",
      "\ttimestamp TEXT, \n",
      "\tid BIGINT, \n",
      "\tdetails TEXT, \n",
      "\tannouncement_timestamp TEXT, \n",
      "\turl_link TEXT, \n",
      "\tuuid TEXT, \n",
      "\tannouncement_url_link TEXT, \n",
      "\tcompany_message TEXT, \n",
      "\tevent_type TEXT, \n",
      "\tevent_type_acronym TEXT, \n",
      "\tevent_type_description TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from temp_table table:\n",
      "timestamp\tid\tdetails\tannouncement_timestamp\turl_link\tuuid\tannouncement_url_link\tcompany_message\tevent_type\tevent_type_acronym\tevent_type_description\n",
      "2023-08-02 15:00:00.000 +0100\t1\tHurrian Network (MLD) Blockchain Migration and Rebrand to VibeToken (VIBE) Supported by Bitrue\t2023-08-02 05:49:00.000 +0100\thttps://support.bitrue.com/hc/en-001/articles/21311781298585-Bitrue-Has-Completed-the-MLD-Token-Migr\t93a91e38-9bd5-41ca-8b1b-240cc419c0c5\thttps://support.bitrue.com/hc/en-001/articles/21311781298585-Bitrue-Has-Completed-the-MLD-Token-Migr\tWe have completed the Hurrian Network (MLD) token migration and rebranding program as Vibe token (VI\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "2022-08-16 07:00:00.000 +0100\t1\tWhole Earth Coin (WEC) Blockchain Migration Supported by MEXC.\t2022-08-16 08:51:00.000 +0100\thttps://support.mexc.com/hc/en-001/articles/9546038014489-MEXC-Will-Support-the-Whole-Earth-Coin-WEC\t6b6720f6-3dd0-42e7-8a46-ea999dc17f39\thttps://support.mexc.com/hc/en-001/articles/9546038014489-MEXC-Will-Support-the-Whole-Earth-Coin-WEC\tMEXC will support the Whole Earth Coin (WEC) contract swap.\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "2022-12-01 14:00:00.000 +0000\t1\tLYFE (LYFE) Migration Supported by Indodax\t2022-11-16 00:00:00.000 +0000\thttps://blog.indodax.com/listing-lyfenew/\td31a9cf6-f318-4355-835e-770d09e75d4b\thttps://blog.indodax.com/lyfe-lland-migration/\tWe hereby inform you that there will be a network migration and a merger between LYFE (Lyfe) and LLA\tBlockchain Migration\tBLKMIG\tMigration of an asset from one blockchain protocol to another blockchain protocol.\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mBased on the schema of the tables, I will insert each new record from the temp_table into the appropriate existing tables. Here is the query to insert the new records into the actions_rows table:\n",
      "\n",
      "```sql\n",
      "INSERT INTO actions_rows (effective_time, static_event_id, description, announce_time, url, event_id, announce_url, comment)\n",
      "SELECT announcement_timestamp, static_action_id, details, timestamp, url_link, uuid, announcement_url_link, company_message\n",
      "FROM temp_table;\n",
      "```\n",
      "\n",
      "And here is the query to insert the new records into the static_actions_rows table:\n",
      "\n",
      "```sql\n",
      "INSERT INTO static_actions_rows (static_action_id, name, acronym, description)\n",
      "SELECT static_action_id, event_type, event_type_acronym, event_type_description\n",
      "FROM temp_table;\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Using the data from the temp_table, insert each new record into the appropiate already existing tables by following the schema.',\n",
       " 'output': 'Based on the schema of the tables, I will insert each new record from the temp_table into the appropriate existing tables. Here is the query to insert the new records into the actions_rows table:\\n\\n```sql\\nINSERT INTO actions_rows (effective_time, static_event_id, description, announce_time, url, event_id, announce_url, comment)\\nSELECT announcement_timestamp, static_action_id, details, timestamp, url_link, uuid, announcement_url_link, company_message\\nFROM temp_table;\\n```\\n\\nAnd here is the query to insert the new records into the static_actions_rows table:\\n\\n```sql\\nINSERT INTO static_actions_rows (static_action_id, name, acronym, description)\\nSELECT static_action_id, event_type, event_type_acronym, event_type_description\\nFROM temp_table;\\n```'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test using an input file and asking the agent to execute queries which will eventually insert data into the database\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = str(here(\"data\")) + \"/input_data/RAG_sample_data_no_match_column_names.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# data\n",
    "# Insert the data into a temporary table\n",
    "data.to_sql(\"temp_table\", con=db._engine, if_exists=\"replace\", index=False)\n",
    "print(\"CSV data has been uploaded to the database.\")\n",
    "\n",
    "# reload the database\n",
    "# NOTE: might be able to do this in a more efficient way\n",
    "db_path = str(here(\"data\")) + \"/csv_xlsx_sqldb.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "db.run(\"SELECT COUNT(*) FROM temp_table;\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True, max_execution_time = 10)\n",
    "\n",
    "# Now we can ask the agent to execute queries that will use this data\n",
    "agent_executor.invoke({\"input\": \"Using the data from the temp_table, insert each new record into the appropiate already existing tables by following the schema.\"})\n",
    "# agent_executor.invoke({\"input\": \"Grab all the records from the temp_table and provide me with a list of SQL insert statements that will insert the data into the appropriate tables.\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-raggpt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
