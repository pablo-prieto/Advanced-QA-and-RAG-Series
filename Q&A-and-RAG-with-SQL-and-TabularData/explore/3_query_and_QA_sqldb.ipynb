{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/use_cases/sql/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from pyprojroot import here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connecting to the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(here(\"data\")) + \"/csv_xlsx_sqldb.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the connection to the vectordb\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM actions_rows LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the access to the environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(\"Environment variables are loaded:\", load_dotenv())\n",
    "print(\"test by reading a variable:\", os.getenv(\"gpt_deployment_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test your GPT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        \"You are a helpful assistant\"\n",
    "    )},\n",
    "    {\"role\": \"user\", \"content\": str(\"hello\")}\n",
    "]\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"gpt_deployment_name\"),\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. SQL query chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = os.getenv(\"gpt_deployment_name\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model_name=model_name,\n",
    "    temperature=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many actions are there?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the query to make sure it’s valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add QuerySQLDataBaseTool to the chain**\n",
    "Execute SQL query\n",
    "\n",
    "**This is the most dangerous part of creating a SQL chain.** Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "We can use the QuerySQLDatabaseTool to easily add query execution to our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "chain = write_query | execute_query\n",
    "\n",
    "chain.invoke({\"question\": \"How many actions are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer the question in a user friendly manner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many actions are there\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Agents**\n",
    "\n",
    "Agent which provides a more flexible way of interacting with SQL databases. The main advantages of using the SQL Agent are:\n",
    "\n",
    "- It can answer questions based on the databases’ schema as well as on the databases’ content (like describing a specific table).\n",
    "- It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
    "- It can answer questions that require multiple dependent queries.\n",
    "- It will save tokens by only considering the schema from relevant tables.\n",
    "\n",
    "To initialize the agent, we use create_sql_agent function. This agent contains the SQLDatabaseToolkit which contains tools to:\n",
    "\n",
    "- Create and execute queries\n",
    "- Check query syntax\n",
    "- Retrieve table descriptions\n",
    "- …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True, max_execution_time = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"How many actions have to do with Blockchains?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Provide me only the most recent action, its description, its comment and the static event description (from static_event_id) in a list.\"})\n",
    "# agent_executor.invoke(\"Describe the playlisttrack table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert temp table into the Database for testing new records upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = str(here(\"data\")) + \"/input_data/RAG_sample_data_no_match_column_names.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# data\n",
    "# Insert the data into a temporary table\n",
    "data.to_sql(\"temp_table\", con=db._engine, if_exists=\"replace\", index=False)\n",
    "print(\"CSV data has been uploaded to the database.\")\n",
    "\n",
    "# reload the database\n",
    "# NOTE: might be able to do this in a more efficient way\n",
    "db_path = str(here(\"data\")) + \"/csv_xlsx_sqldb.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "db.run(\"SELECT COUNT(*) FROM temp_table;\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test new temp_table and being able to insert them as records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True, max_execution_time = 10)\n",
    "\n",
    "# Now we can ask the agent to execute queries that will use this data\n",
    "# agent_executor.invoke({\"input\": \"You are a Data Analyst with SQL expertise. I need you to provide me with the proper SQL insert statements code (with no specific values) for some new data that is stored in the temp_table. Use the schema as a reference to know which column from the temp_table goes into which column from the other tables. Using the data from the temp_table, provide me only the proper SQL insert statements to insert them into the appropriate table (except the temp_table).\"})\n",
    "\n",
    "# agent_executor.invoke({\"input\": \"You are a Data Analyst with SQL expertise. We've added new data that is stored in the temp_table. Programmatically speaking, how would you generate the proper SQL insert statements to insert the records in temp_table into the other tables?\"})\n",
    "\n",
    "response = agent_executor.invoke({\"input\": \"You are a Data Analyst with SQL expertise. Provide me a mapping of all columns from the temp_table to the other tables by analyzing the existing records. Provide me only the answer in JSON format(without new lines) using the following example: {'temp_table.column_name': 'other_table.column_name'}\"})\n",
    "\n",
    "# response = agent_executor.invoke({\"input\": \"You are a Data Analyst with SQL expertise. Pull 20 records from the temp_table and match each column to the appropriate column from the other tables (can only match 1). Then, provide me a mapping of all columns from the temp_table to the other tables. Provide me only the answer in JSON format(without new lines) using the following example: {'temp_table.column_name': 'other_table.column_name'}\"})\n",
    "\n",
    "# response = agent_executor.invoke({\"input\": \"Which table column from either actions_rows or static_actions_rows matches the temp_table announcement_timestamp column?\"})\n",
    "\n",
    "print(response[\"output\"])\n",
    "\n",
    "# print(json.loads(response[\"output\"]))\n",
    "\n",
    "# # Extract the 'output' and process it as JSON\n",
    "# output_raw = response.get('output')  # Assuming 'output' is part of the response\n",
    "# try:\n",
    "#     # Clean up the output (in case it includes extra text like explanations)\n",
    "#     json_start_index = output_raw.find('{')  # Locate the JSON part\n",
    "#     json_data = output_raw[json_start_index:]  # Extract JSON-like content\n",
    "\n",
    "#     # Parse the JSON\n",
    "#     mapping = json.loads(json_data)\n",
    "#     print(mapping)\n",
    "# except (json.JSONDecodeError, AttributeError) as e:\n",
    "#     print(\"Error parsing JSON:\", e)\n",
    "#     print(\"Raw Output:\", output_raw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-raggpt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
